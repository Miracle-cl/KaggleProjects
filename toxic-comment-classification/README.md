A large number of Wikipedia comments which have been labeled by human raters for toxic behavior.

The types of toxicity are:
- toxic
- severe_toxic
- obscene
- threat
- insult
- identity_hate


Create a model (Logistics Regression, LSTM-Attention) which predicts a probability of each type of toxicity for each comment.


Create a model (BiGRU) by pytorch.